{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:10:54.408071Z",
     "start_time": "2021-02-21T02:10:34.268081Z"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "alt.renderers.enable('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:14:12.065996Z",
     "start_time": "2021-02-21T02:10:54.417083Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "folder_path = './datasets/Caltech-101-ObjectCategories'\n",
    "\n",
    "# Note: Caltech-101 dataset images are not of the same size\n",
    "\n",
    "X_raw = []\n",
    "for filename in os.listdir(f'{folder_path}/imgs'):\n",
    "    X_raw.append(cv.imread(f'{folder_path}/imgs/{filename}'))\n",
    "X_raw = np.array(X_raw)\n",
    "\n",
    "with open(f'{folder_path}/labels.json') as f:\n",
    "    y = json.load(f)\n",
    "y = np.array([d['label'] for d in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:14:12.096908Z",
     "start_time": "2021-02-21T02:14:12.070911Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "n_samples = 2000\n",
    "indices = np.random.choice([i for i in range(len(X_raw))], size=n_samples, replace=False)\n",
    "\n",
    "X_raw = X_raw[indices]\n",
    "y = y[indices]\n",
    "'''\n",
    "X_raw = X_raw[1000:2000]\n",
    "y = y[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T09:15:49.974747Z",
     "start_time": "2021-02-18T09:15:48.437600Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X_raw = digits.images\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:55:32.597541Z",
     "start_time": "2021-02-18T08:55:30.994311Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_raw = np.vstack((x_train, x_test))\n",
    "X = X_raw.reshape(X_raw.shape[0], -1)\n",
    "y = np.concatenate((y_train, y_test)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T09:15:54.336146Z",
     "start_time": "2021-02-18T09:15:53.923183Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_raw = np.vstack((x_train, x_test))\n",
    "X = X_raw.reshape(X_raw.shape[0], -1)\n",
    "y = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Points\n",
    "\n",
    "- data source: flattened image\n",
    "    - variation: the color space of the image (RGB, GRAY, HSV, LUV)\n",
    "- postprocess: no postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:14:24.102969Z",
     "start_time": "2021-02-21T02:14:12.113910Z"
    }
   },
   "outputs": [],
   "source": [
    "from feature_extraction import raw_flatten\n",
    "\n",
    "X, feature_names = raw_flatten(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:14:24.865984Z",
     "start_time": "2021-02-21T02:14:24.116975Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "print('feature representation shape: ', X.shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X) if X.shape[1] > 2 else X\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0],\n",
    "    'dim-2': X_proj[:, 1],\n",
    "    'label': y,\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction\n",
    "\n",
    "- data source: flattened image\n",
    "    - variation: the color space of the image (RGB, GRAY, HSV, LUV)\n",
    "- postprocess: dimension reduction\n",
    "    - variation\n",
    "        - the dimension reduction method (PCA, MDS, t-SNE, isomap)\n",
    "        - the number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:14:27.623344Z",
     "start_time": "2021-02-21T02:14:24.884991Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from feature_extraction import resize_SVD\n",
    "\n",
    "X, feature_names = resize_SVD(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:14:27.949351Z",
     "start_time": "2021-02-21T02:14:27.635341Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "print('feature representation shape: ', X.shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X) if X.shape[1] > 2 else X\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0],\n",
    "    'dim-2': X_proj[:, 1],\n",
    "    'label': y,\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction with Pretrained CNN\n",
    "\n",
    "- data source: image\n",
    "- postprocess: feature extraction with CNN\n",
    "    - variation\n",
    "        - the pretrained model\n",
    "        - the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_cnn_output(imgs: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Extract features for each image by convolution layer output of pretrained CNN.\n",
    "\n",
    "    The images are converted to grey image and resized to 224 x 224\n",
    "    to match the size of the original input to the CNN.\n",
    "    \n",
    "    The dimension reduction is conducted on the CNN output.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    imgs : np.ndarray\n",
    "        The images to extract features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray\n",
    "        The extracted feature values.\n",
    "    feature_names : List[str]\n",
    "        The names of features.\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = 224, 224\n",
    "    imgs_resized = []\n",
    "    for img in imgs:\n",
    "        if len(img.shape) == 2:\n",
    "            img_color = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            img_color = img\n",
    "        img_resized = cv.resize(img_color, (h, w), interpolation=cv.INTER_AREA)\n",
    "        imgs_resized.append(img_resized)\n",
    "    imgs_resized = np.array(imgs_resized)\n",
    "    X_raw_processed = preprocess_input(imgs_resized.astype(float))\n",
    "    \n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    X_vgg16 = model.predict(X_raw_processed)\n",
    "    n_samples = X_vgg16.shape[0]\n",
    "    X_vgg16 = X_vgg16.reshape(n_samples, -1)\n",
    "\n",
    "    dims = 50\n",
    "    reducer = decomposition.TruncatedSVD(n_components=dims)\n",
    "    X_proj = reducer.fit_transform(X)\n",
    "\n",
    "    feature_names = [f'cnn-dim-{i}' for i in range(dims)]\n",
    "    return X_proj, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T08:51:12.299611Z",
     "start_time": "2021-02-20T08:49:09.854747Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "target_size = (224, 224)\n",
    "\n",
    "X_raw_processed = X_raw[: 10]\n",
    "\n",
    "# turn gray image into color image\n",
    "if len(X_raw.shape) == 3:\n",
    "    X_raw_processed = np.array(list(map(lambda img: cv.cvtColor(img, cv.COLOR_GRAY2BGR),\n",
    "                                    X_raw_processed)))\n",
    "X_raw_processed = np.array(list(map(lambda img: cv.resize(img, target_size, interpolation=cv.INTER_AREA),\n",
    "                                    X_raw_processed)))\n",
    "X_raw_processed = preprocess_input(X_raw_processed.astype(float))\n",
    "\n",
    "X_vgg16 = model.predict(X_raw_processed)\n",
    "n_samples = X_vgg16.shape[0]\n",
    "X_vgg16 = X_vgg16.reshape(n_samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-20T05:43:33.917Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'shape of extracted feature representation: {X_vgg16.shape}')\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X_vgg16)\n",
    "\n",
    "n_samples = 1000\n",
    "indices = np.random.choice([i for i in range(len(X))], size=n_samples, replace=False)\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0],\n",
    "    'dim-2': X_proj[:, 1],\n",
    "    'label': y[:, 1000],\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Features\n",
    "\n",
    "- data source: flattened image\n",
    "- postprocess: statistical measurements\n",
    "    - variation\n",
    "        - histogram\n",
    "        - median\n",
    "        - moments\n",
    "            - mean\n",
    "            - std\n",
    "            - skewness\n",
    "        - correlogram\n",
    "        - coherence vector\n",
    "    - variation\n",
    "        - the color space\n",
    "    - variation\n",
    "        - value quantization\n",
    "- note: the features can be computed in different color spaces (e.g., RGB, HSV, LUV)\n",
    "- remark: Hu moments often output nan which is not desirable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:20:12.823046Z",
     "start_time": "2021-02-21T02:14:27.966354Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from feature_extraction import color_descriptors\n",
    "\n",
    "X, feature_names = color_descriptors(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:20:13.025046Z",
     "start_time": "2021-02-21T02:20:12.829029Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder().fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "rvalues = [pearsonr(X[:, i], y_encoded)[0] for i in range(len(feature_names))]\n",
    "for i in range(len(feature_names)):\n",
    "    print(f'{feature_names[i]} corr-y: {rvalues[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:20:13.244032Z",
     "start_time": "2021-02-21T02:20:13.033029Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "print('feature representation shape: ', X.shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X) if X.shape[1] > 2 else X\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0][600:],\n",
    "    'dim-2': X_proj[:, 1][600:],\n",
    "    'label': y[600:],\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:20:41.741460Z",
     "start_time": "2021-02-21T02:20:13.259059Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition, manifold\n",
    "\n",
    "hist_feature_indices = [i for i in range(len(feature_names)) if feature_names[i].find('hist') != -1]\n",
    "\n",
    "print('feature representation shape: ', X[:, hist_feature_indices].shape)\n",
    "\n",
    "#reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "reducer = manifold.TSNE(n_components=2, random_state=0)\n",
    "X_proj = reducer.fit_transform(X[:, hist_feature_indices])\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0][600:],\n",
    "    'dim-2': X_proj[:, 1][600:],\n",
    "    'label': y[600:],\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='color histogram features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:21:12.181922Z",
     "start_time": "2021-02-21T02:20:41.752427Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition, manifold\n",
    "\n",
    "nonhist_feature_indices = [i for i in range(len(feature_names)) if feature_names[i].find('hist') == -1]\n",
    "\n",
    "print('feature representation shape: ', X[:, nonhist_feature_indices].shape)\n",
    "\n",
    "#reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "reducer = manifold.TSNE(n_components=2, random_state=0)\n",
    "X_proj = reducer.fit_transform(X[:, nonhist_feature_indices])\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0][600:],\n",
    "    'dim-2': X_proj[:, 1][600:],\n",
    "    'label': y[600:],\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='color statistics features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T07:37:52.359537Z",
     "start_time": "2021-02-18T07:37:51.789095Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# quantized histogram\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "n_samples = 10000\n",
    "n_colors = 50\n",
    "\n",
    "colors = X_raw.reshape(-1, 3)\n",
    "#colors_sample = shuffle(colors, random_state=0)[:n_samples]\n",
    "#indices = np.random.choice([i for i in range(len(colors))], size=n_samples, replace=False)\n",
    "# note: generate random sampling indices with replacement for speed consideration\n",
    "indices = [np.random.randint(0, len(colors)-1) for i in range(n_samples)]\n",
    "colors_sample = colors[indices]\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(colors_sample)\n",
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# correlogram\n",
    "\n",
    "# https://medium.com/@shashwat17103/the-dummys-guide-to-colour-correlogram-from-scratch-in-python-1b20a55eb00c\n",
    "\n",
    "# coherence vector\n",
    "\n",
    "def ccv(src, tau=0, n=64):\n",
    "    \"\"\"\n",
    "    Proccess of Computing CCV(color coherence vector)\n",
    "\n",
    "    1. Blur\n",
    "    2. Quantizing color\n",
    "    3. Thresholding\n",
    "    4. Labeling\n",
    "    5. Counting\n",
    "    \"\"\"\n",
    "\n",
    "    img = src.copy()\n",
    "    row, col, channels = img.shape\n",
    "    if not col == 300:\n",
    "        aspect = 300.0//col\n",
    "        img = cv2.resize(img, None, fx=aspect, fy=aspect, interpolation = cv2.INTER_CUBIC)\n",
    "    row, col, channels = img.shape\n",
    "    # blur\n",
    "    img = cv2.GaussianBlur(img, (3,3),0)\n",
    "    # quantize color\n",
    "    img = QuantizeColor(img, n)\n",
    "    bgr = cv2.split(img)\n",
    "    #bgr = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n",
    "    if tau == 0:\n",
    "        tau = row*col * 0.1\n",
    "    alpha = np.zeros(n)\n",
    "    beta = np.zeros(n)\n",
    "    # labeling\n",
    "    for i,ch in enumerate(bgr):\n",
    "        ret,th = cv2.threshold(ch,127,255,0)\n",
    "        ret, labeled, stat, centroids = cv2.connectedComponentsWithStats(th, None, cv2.CC_STAT_AREA, None, connectivity=8)\n",
    "        # generate ccv\n",
    "        areas = [[v[4],label_idx] for label_idx,v in enumerate(stat)]\n",
    "        coord = [[v[0],v[1]] for label_idx,v in enumerate(stat)]\n",
    "        # Counting\n",
    "        for a,c in zip(areas, coord):\n",
    "        area_size = a[0]\n",
    "        x,y = c[0], c[1]\n",
    "        if (x < ch.shape[1]) and (y < ch.shape[0]):\n",
    "            bin_idx = int(ch[y,x]//(256//n))\n",
    "            if area_size >= tau:\n",
    "            alpha[bin_idx] = alpha[bin_idx] + area_size\n",
    "            else:\n",
    "            beta[bin_idx] = beta[bin_idx] + area_size\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Strength Features\n",
    "\n",
    "- data source: flattened edge image\n",
    "- postprocess: statistical measurements\n",
    "    - variation\n",
    "        - histogram\n",
    "        - moments\n",
    "        - correlogram\n",
    "        - coherence vector\n",
    "    - variation\n",
    "        - the edge detection method\n",
    "    - variation\n",
    "        - value quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:21:55.600862Z",
     "start_time": "2021-02-21T02:21:12.190920Z"
    }
   },
   "outputs": [],
   "source": [
    "from feature_extraction import edge_descriptors\n",
    "\n",
    "X, feature_names = edge_descriptors(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:21:55.679913Z",
     "start_time": "2021-02-21T02:21:55.610865Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder().fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "rvalues = [pearsonr(X[:, i], y_encoded)[0] for i in range(len(feature_names))]\n",
    "for i in range(len(feature_names)):\n",
    "    print(f'{feature_names[i]} corr-y: {rvalues[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:21:56.067862Z",
     "start_time": "2021-02-21T02:21:55.702903Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "print('feature representation shape: ', X.shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X) if X.shape[1] > 2 else X\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0],\n",
    "    'dim-2': X_proj[:, 1],\n",
    "    'label': y,\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='edge features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:21:56.381875Z",
     "start_time": "2021-02-21T02:21:56.090864Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition, manifold\n",
    "\n",
    "hist_feature_indices = [i for i in range(len(feature_names)) if feature_names[i].find('hist') != -1]\n",
    "\n",
    "print('feature representation shape: ', X[:, hist_feature_indices].shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "#reducer = manifold.TSNE(n_components=2, random_state=0)\n",
    "X_proj = reducer.fit_transform(X[:, hist_feature_indices])\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0][600:],\n",
    "    'dim-2': X_proj[:, 1][600:],\n",
    "    'label': y[600:],\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='edge histogram features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:21:56.691863Z",
     "start_time": "2021-02-21T02:21:56.392860Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition, manifold\n",
    "\n",
    "nonhist_feature_indices = [i for i in range(len(feature_names)) if feature_names[i].find('hist') == -1]\n",
    "\n",
    "print('feature representation shape: ', X[:, nonhist_feature_indices].shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "#reducer = manifold.TSNE(n_components=2, random_state=0)\n",
    "X_proj = reducer.fit_transform(X[:, nonhist_feature_indices])\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0][600:],\n",
    "    'dim-2': X_proj[:, 1][600:],\n",
    "    'label': y[600:],\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='edge statistics features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Direction Features\n",
    "\n",
    "- data source: flattened edge direction image\n",
    "- postprocess: statistical measurements\n",
    "    - variation\n",
    "        - histogram\n",
    "        - moments\n",
    "        - correlogram\n",
    "        - coherence vector\n",
    "    - variation\n",
    "        - the edge detection method\n",
    "    - variation\n",
    "        - value quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:22:35.931491Z",
     "start_time": "2021-02-21T02:21:56.711866Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from feature_extraction import edge_direction_descriptors\n",
    "\n",
    "X, feature_names = edge_direction_descriptors(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:22:36.155517Z",
     "start_time": "2021-02-21T02:22:35.944491Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder().fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "rvalues = [pearsonr(X[:, i], y_encoded)[0] for i in range(len(feature_names))]\n",
    "for i in range(len(feature_names)):\n",
    "    print(f'{feature_names[i]} corr-y: {rvalues[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:22:36.571602Z",
     "start_time": "2021-02-21T02:22:36.178122Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "print('feature representation shape: ', X.shape)\n",
    "\n",
    "reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X) if X.shape[1] > 2 else X\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0],\n",
    "    'dim-2': X_proj[:, 1],\n",
    "    'label': y,\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='edge direction features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from skimage.measure import moments\n",
    "\n",
    "m = moments(img_gray, order=2)\n",
    "\n",
    "# center\n",
    "x = m[1, 0] / m[0, 0]\n",
    "y = m[0, 1] / m[0, 0]\n",
    "\n",
    "# central moments\n",
    "a = m[2, 0] / m[0, 0] - x ** 2\n",
    "b = 2 * (m[1, 1] / m[0, 0] - x * y)\n",
    "c = m[0, 2] / m[0, 0] - y ** 2\n",
    "\n",
    "# image orientation\n",
    "if a == c:\n",
    "    theta = math.pi / 2\n",
    "else:\n",
    "    theta = 1 / 2 * math.atan(b / (a - c)) + (a < c) * math.pi / 2\n",
    "angle = theta / math.pi * 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Features\n",
    "\n",
    "- local binary patterns\n",
    "- grey-level co-occurrence matrix\n",
    "- frequency domain descriptors\n",
    "- entropy\n",
    "- local entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:32:14.604265Z",
     "start_time": "2021-02-21T02:22:36.589594Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from feature_extraction import texture_descriptors\n",
    "\n",
    "X, feature_names = texture_descriptors(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:32:14.669251Z",
     "start_time": "2021-02-21T02:32:14.608230Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder().fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "rvalues = [pearsonr(X[:, i], y_encoded)[0] for i in range(len(feature_names))]\n",
    "for i in range(len(feature_names)):\n",
    "    print(f'{feature_names[i]} corr-y: {rvalues[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T02:32:33.654295Z",
     "start_time": "2021-02-21T02:32:14.677232Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition, manifold\n",
    "\n",
    "print('feature representation shape: ', X.shape)\n",
    "\n",
    "reducer = manifold.TSNE(n_components=2, random_state=0)\n",
    "#reducer = decomposition.TruncatedSVD(n_components=2)\n",
    "X_proj = reducer.fit_transform(X) if X.shape[1] > 2 else X\n",
    "\n",
    "chart = alt.Chart(pd.DataFrame({\n",
    "    'dim-1': X_proj[:, 0],\n",
    "    'dim-2': X_proj[:, 1],\n",
    "    'label': y,\n",
    "})).mark_point().encode(\n",
    "    x='dim-1:Q',\n",
    "    y='dim-2:Q',\n",
    "    color='label:N',\n",
    ").properties(\n",
    "    title='texture features'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = np.fft.fft2(img_gray)\n",
    "fshift = np.fft.fftshift(f)\n",
    "magnitude_spectrum = 20 * np.log(np.abs(fshift))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img_gray, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Specific Features\n",
    "\n",
    "- TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
